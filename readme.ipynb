{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Self-Driving Car Nano Degree - Project 1\n",
    "\n",
    "## Finding Lane Lines on the Road\n",
    "---\n",
    "In this project, you will use the tools you learned about in the lesson to identify lane lines on the road.  You can develop your pipeline on a series of individual images, and later apply the result to a video stream (really just a series of images). Check out the video clip \"raw-lines-example.mp4\" (also contained in this repository) to see what the output should look like after using the helper functions below. \n",
    "\n",
    "Once you have a result that looks roughly like \"raw-lines-example.mp4\", you'll need to get creative and try to average and/or extrapolate the line segments you've detected to map out the full extent of the lane lines.  You can see an example of the result you're going for in the video \"P1_example.mp4\".  Ultimately, you would like to draw just one line for the left side of the lane, and one for the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The tools you have are color selection, region of interest selection, grayscaling, Gaussian smoothing, Canny Edge Detection and Hough Tranform line detection.  You  are also free to explore and try other techniques that were not presented in the lesson.  Your goal is piece together a pipeline to detect the line segments in the image, then average/extrapolate them and draw them onto the image for display (as below).  Once you have a working pipeline, try it out on the video stream below.**\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"line-segments-example.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output should look something like this (above) after detecting line segments using the helper functions below </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n",
    "<figure>\n",
    " <img src=\"laneLines_thirdPass.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your goal is to connect/average/extrapolate line segments to get output like this</p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "## **Finding Lane Lines on the Road **\n",
    "<img src=\"laneLines_thirdPass.jpg\" width=\"480\" alt=\"Combined Image\" />\n",
    "\n",
    "When we drive, we use our eyes to decide where to go.  The lines on the road that show us where the lanes are act as our constant reference for where to steer the vehicle.  Naturally, one of the first things we would like to do in developing a self-driving car is to automatically detect lane lines using an algorithm.\n",
    "\n",
    "In this project you will detect lane lines in images using Python and OpenCV.  OpenCV means \"Open-Source Computer Vision\", which is a package that has many useful tools for analyzing images.  \n",
    "\n",
    "**Setup**\n",
    "**Step 1:** Getting setup with Python\n",
    "\n",
    "To do this project, you will need Python 3 along with the numpy, matplotlib, and OpenCV libraries, as well as Jupyter Notebook installed. \n",
    "\n",
    "We recommend downloading and installing the Anaconda Python 3 distribution from Continuum Analytics because it comes prepackaged with many of the Python dependencies you will need for this and future projects, makes it easy to install OpenCV, and includes Jupyter Notebook.  Beyond that, it is one of the most common Python distributions used in data analytics and machine learning, so a great choice if you're getting started in the field.\n",
    "\n",
    "Choose the appropriate Python 3 Anaconda install package for your operating system <A HREF=\"https://www.continuum.io/downloads\" target=\"_blank\">here</A>.   Download and install the package.\n",
    "\n",
    "If you already have Anaconda for Python 2 installed, you can create a separate environment for Python 3 and all the appropriate dependencies with the following command:\n",
    "\n",
    "`>  conda create --name=yourNewEnvironment python=3 anaconda`\n",
    "\n",
    "`>  source activate yourNewEnvironment`\n",
    "\n",
    "**Step 2:** Installing OpenCV\n",
    "\n",
    "Once you have Anaconda installed, first double check you are in your Python 3 environment:\n",
    "\n",
    "`>python`    \n",
    "`Python 3.5.2 |Anaconda 4.1.1 (x86_64)| (default, Jul  2 2016, 17:52:12)`  \n",
    "`[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwin`  \n",
    "`Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.`  \n",
    "`>>>`   \n",
    "(Ctrl-d to exit Python)\n",
    "\n",
    "run the following commands at the terminal prompt to get OpenCV:\n",
    "\n",
    "`> pip install pillow`  \n",
    "`> conda install -c https://conda.anaconda.org/menpo opencv3`\n",
    "\n",
    "then to test if OpenCV is installed correctly:\n",
    "\n",
    "`> python`  \n",
    "`>>> import cv2`  \n",
    "`>>>`  \n",
    "(Ctrl-d to exit Python)\n",
    "\n",
    "**Step 3:** Installing moviepy  \n",
    "\n",
    "We recommend the \"moviepy\" package for processing video in this project (though you're welcome to use other packages if you prefer).  \n",
    "\n",
    "To install moviepy run:\n",
    "\n",
    "`>pip install moviepy`  \n",
    "\n",
    "and check that the install worked:\n",
    "\n",
    "`>python`  \n",
    "`>>>import moviepy`  \n",
    "`>>>`  \n",
    "(Ctrl-d to exit Python)\n",
    "\n",
    "**Step 4:** Opening the code in a Jupyter Notebook\n",
    "\n",
    "You will complete this project in a Jupyter notebook.  If you are unfamiliar with Jupyter Notebooks, check out <A HREF=\"https://www.packtpub.com/books/content/basics-jupyter-notebook-and-python\" target=\"_blank\">Cyrille Rossant's Basics of Jupyter Notebook and Python</A> to get started.\n",
    "\n",
    "Jupyter is an ipython notebook where you can run blocks of code and see results interactively.  All the code for this project is contained in a Jupyter notebook. To start Jupyter in your browser, run the following command at the terminal prompt (be sure you're in your Python 3 environment!):\n",
    "\n",
    "`> jupyter notebook`\n",
    "\n",
    "A browser window will appear showing the contents of the current directory.  Click on the file called \"P1.ipynb\".  Another browser window will appear displaying the notebook.  Follow the instructions in the notebook to complete the project.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Miscellaneous\n",
    "This command line combines the raw and processed videos side-by-side.\n",
    "\n",
    "ffmpeg -i solidYellowLeft.mp4 -i yellow.mp4 -filter_complex \"[0:v:0]pad=iw*2:ih[bg]; [bg][1:v:0]overlay=w\" output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sdc_term1]",
   "language": "python",
   "name": "conda-env-sdc_term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
